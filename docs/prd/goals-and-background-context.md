# Goals and Background Context

## Goals

* **PRIMARY GOAL: High-Fidelity Validation** - To produce a production-quality, validated dataset that serves as the trusted foundation for training and backtesting the core RL agent, built entirely on real historical data.
* To ensure the prepared historical data achieves the highest possible fidelity, precisely mirroring the structure, format, and granularity of a real-time data feed through validation against actual market data.
* To bridge the gap between Crypto Lake's snapshot-based historical data format and Binance's differential real-time feed through sophisticated reconstruction techniques based on comprehensive data profiling.
* To enable RL agent training that achieves post-training backtest VWAP slippage â‰¤ -5 basis points vs baseline on 30 unseen days, demonstrating clear outperformance using a dataset derived from actual market conditions.
* To successfully enable the development of the "Minimum Viable Proof" backtesting engine, which is the key asset for securing a seed investment round.
* To create a robust data pipeline that acquires, validates, and prepares 12 months of historical BTC-USDT L2 order book data using **actual** Crypto Lake data sources.
* **COMPLETED: Data Acquisition** - Successfully established and maintain access to actual Crypto Lake historical data as the foundational prerequisite for all subsequent work.

## Background Context

The RLX Co-Pilot project aims to solve the problem of trade execution slippage by using a Reinforcement Learning agent. The success of this entire venture hinges on proving that the RL agent can demonstrably outperform standard industry benchmarks like VWAP. This proof will be generated by a backtesting engine trained on historical data.

Therefore, the quality and realism of that historical data are paramount. If the training data does not accurately reflect the conditions the agent will see in a live market, the "sim-to-real" gap will be too large, and the model's performance will be unreliable. This data pipeline project is the foundational step to mitigate that risk by creating a clean, high-fidelity dataset that serves as a trustworthy proxy for real-world market conditions.

**CRITICAL EXECUTION LEARNING**: The project has identified a critical execution gap where validation work has been performed on synthetic data while actual Crypto Lake data remains unacquired. This PRD update prioritizes data acquisition as the absolute first step to prevent this gap from recurring. All subsequent work must be grounded in actual historical data to ensure the final dataset represents real market conditions rather than synthetic assumptions.

**CRITICAL TECHNICAL CHALLENGE**: The project must reconcile two fundamentally different data paradigms:
- **Historical Data (Crypto Lake)**: Provides separate trades table and periodic L2 book snapshots (top 20 levels) with exchange timestamps
- **Live Data (Binance WebSocket)**: Provides interleaved stream of differential book updates and individual trades with guaranteed chronological ordering

The reconstruction methodology must bridge this gap through the Chronological Event Replay algorithm, using live "golden samples" to validate fidelity through comprehensive statistical metrics (K-S tests, market microstructure analysis).
