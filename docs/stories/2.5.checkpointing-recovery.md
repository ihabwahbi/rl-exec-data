# Story 2.5: Checkpointing & Recovery

## Status
Draft

## Story
**As a** data engineer,
**I want** the pipeline to implement copy-on-write checkpointing with non-blocking state persistence,
**so that** the system can recover from any failure and resume processing from the last checkpoint without data loss or performance degradation

## Acceptance Criteria
1. The pipeline implements copy-on-write (COW) checkpointing for non-blocking state persistence
2. Checkpoints are created every 5 minutes or after processing 1M events (whichever comes first)
3. State snapshots complete in <100ms without blocking the main processing pipeline
4. Checkpoints include order book state, pipeline progress, and performance metrics
5. Recovery process can locate the latest valid checkpoint and resume processing from that point
6. Checkpoint data is stored using Parquet format with atomic write operations
7. System maintains only the last 3 checkpoints to manage disk usage
8. Checkpoint and recovery process is fully tested with crash simulations
9. Performance impact of checkpointing is <1% on overall throughput
10. Recovery validates data continuity between checkpoint and resume point

## Tasks / Subtasks
- [ ] Task 1: Design Checkpoint Architecture (AC: 1, 3)
  - [ ] Design copy-on-write state snapshot mechanism
  - [ ] Define checkpoint data structures and schemas
  - [ ] Plan integration points with existing pipeline stages
  - [ ] Document non-blocking persistence approach

- [ ] Task 2: Implement CheckpointManager Class (AC: 2, 6, 7)
  - [ ] Create `src/rlx_datapipe/reconstruction/checkpoint_manager.py`
  - [ ] Implement time-based and event-based checkpoint triggers
  - [ ] Add atomic Parquet write with temp file + rename pattern
  - [ ] Implement checkpoint cleanup to maintain only last 3

- [ ] Task 3: Implement State Snapshot Mechanism (AC: 1, 3, 4)
  - [ ] Implement COW snapshot for order book state
  - [ ] Capture pipeline progress (file offset, event count)
  - [ ] Include performance metrics in checkpoint
  - [ ] Ensure snapshot creation completes in <100ms

- [ ] Task 4: Integrate Checkpointing into Pipeline (AC: 2, 9)
  - [ ] Add checkpoint triggers to Order Book Engine
  - [ ] Integrate CheckpointManager with existing pipeline stages
  - [ ] Implement async checkpoint writes to avoid blocking
  - [ ] Add performance monitoring for checkpoint impact

- [ ] Task 5: Implement Recovery Process (AC: 5, 10)
  - [ ] Create recovery logic to find latest valid checkpoint
  - [ ] Implement state restoration from Parquet checkpoint
  - [ ] Add file seek and resume functionality
  - [ ] Validate data continuity after recovery

- [ ] Task 6: Add WAL Support (AC: 1, 5)
  - [ ] Implement Write-Ahead Log using Parquet segments
  - [ ] Add atomic "DONE" markers for crash recovery
  - [ ] Ensure WAL integrates with checkpoint system

- [ ] Task 7: Multi-Symbol Checkpoint Support (AC: 1, 4)
  - [ ] Extend CheckpointManager for multi-symbol architecture
  - [ ] Implement per-symbol checkpoint management
  - [ ] Ensure process isolation for checkpoint operations

- [ ] Task 8: Write Comprehensive Tests (AC: 8, 9, 10)
  - [ ] Unit tests for CheckpointManager
  - [ ] Integration tests for checkpoint/recovery cycle
  - [ ] Crash simulation tests (kill -9 scenarios)
  - [ ] Performance impact tests (<1% degradation)
  - [ ] 24-hour memory leak tests
  - [ ] Data continuity validation tests

## Dev Notes

### Previous Story Insights
From Story 2.4 (Multi-Symbol Architecture):
- Pipeline now supports multiple symbols with process isolation
- Each symbol runs in its own process with 1GB memory limit
- ProcessManager handles worker lifecycle and crash recovery
- Queue-based architecture enables clean checkpoint integration points
- Symbol workers already have checkpoint_manager placeholder in implementation

### Architecture Context

**Checkpoint Integration Points** [Source: architecture/streaming-architecture.md#checkpoint-recovery]
```
[Disk Reader] → [Parser] → [Order Book Engine] → [Event Formatter] → [Parquet Writer]
                              ↓
                          Checkpoint
                          Manager
```

### Technical Specifications

**CheckpointManager Implementation** [Source: architecture/streaming-architecture.md#lines-146-167]
```python
class CheckpointManager:
    """Manage pipeline state for crash recovery."""
    
    def __init__(self, checkpoint_dir: Path):
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_interval = 300  # 5 minutes
        
    async def save_checkpoint(self, pipeline_state: Dict):
        """Atomic checkpoint write."""
        checkpoint_file = self.checkpoint_dir / f"checkpoint_{time.time()}.parquet"
        temp_file = checkpoint_file.with_suffix('.tmp')
        
        # Write state to Parquet (more efficient than pickle)
        pd.DataFrame([pipeline_state]).to_parquet(temp_file)
        
        # Atomic rename
        temp_file.rename(checkpoint_file)
        
        # Keep only last 3 checkpoints
        self.cleanup_old_checkpoints()
```

**State Components to Persist** [Source: architecture/components.md#reconstructor-state]
1. **Order Book State**:
   - Current bid/ask levels (top 20)
   - Last processed update_id
   - Last processed timestamp

2. **Pipeline Progress**:
   - Current file being processed
   - Offset within file  
   - Events processed count

3. **Performance Metrics**:
   - Gap statistics
   - Drift metrics
   - Processing rate counters

**Copy-on-Write Strategy** [Source: architecture/components.md#lines-166-171]
- [ASSUMPTION][R-OAI-03] Copy-on-Write Checkpointing for non-blocking persistence
- Allows pipeline to continue processing during state persistence
- Critical for maintaining 100k+ events/second throughput
- Target <100ms pause for COW snapshot creation

**WAL Design** [Source: architecture/components.md#wal-implementation]
- Simple append-only Parquet segments
- Atomic "DONE" markers for crash recovery
- Avoids RocksDB C++ dependency
- Integrates with checkpoint system for durability

### Performance Requirements

**Checkpoint Frequency** [Source: architecture/streaming-architecture.md#lines-73-75]
- Time-based: Every 5 minutes
- Event-based: Every 1M events processed
- On-demand: Before shutdown or when requested

**Performance Targets** [Source: architecture/performance-optimization.md]
- Checkpoint must not block main processing pipeline
- Use async I/O for checkpoint writes
- <100ms snapshot creation time
- <100MB checkpoint size for fast recovery
- <1% throughput impact

### Memory Management Strategy

**Double-Buffering Approach** [Source: architecture/performance-optimization.md#lines-73-96]
- Pre-allocate memory pools to avoid allocation during checkpointing
- Use separate memory regions for active processing and snapshots
- Implement double-buffering for zero-copy snapshots

### Recovery Process

**Recovery Steps** [Source: architecture/streaming-architecture.md#recovery-logic]
1. Locate latest valid checkpoint with "DONE" marker
2. Restore order book state from checkpoint
3. Restore pipeline progress (file offset, event count)
4. Seek to saved position in input files
5. Validate no gaps between checkpoint and resume point
6. Resume normal processing

### File Locations

**New Files** [Source: architecture/source-tree.md pattern]
- `src/rlx_datapipe/reconstruction/checkpoint_manager.py` - Main checkpoint logic
- `src/rlx_datapipe/reconstruction/wal_manager.py` - Write-ahead log support
- `tests/reconstruction/test_checkpoint_manager.py` - Unit tests
- `tests/reconstruction/test_checkpoint_recovery.py` - Integration tests

**Modified Files**:
- `src/rlx_datapipe/reconstruction/order_book_engine.py` - Add checkpoint hooks
- `src/rlx_datapipe/reconstruction/symbol_worker.py` - Integrate checkpoint triggers
- `src/rlx_datapipe/reconstruction/pipeline_integration.py` - Add recovery logic

### Testing Requirements

**Test Framework**: Pytest 8.2+ [Source: architecture/test-strategy.md]  
**Test Location**: `tests/reconstruction/` mirroring source structure  
**Coverage Target**: 80%+ for checkpoint/recovery code  

**Test Categories** [Source: architecture/streaming-architecture.md#lines-212-218]:
1. **Unit Tests**:
   - CheckpointManager methods
   - State snapshot mechanisms
   - WAL operations

2. **Integration Tests**:
   - Full checkpoint/recovery cycle
   - Multi-symbol checkpoint coordination
   - Pipeline resume validation

3. **Reliability Tests**:
   - Memory leak tests (24-hour run)
   - Crash recovery (kill -9 scenarios)
   - Data consistency validation

4. **Performance Tests**:
   - Throughput impact (<1% degradation)
   - Snapshot timing (<100ms)
   - Recovery speed benchmarks

**Test Patterns**:
```python
def test_crash_recovery():
    # Start pipeline with checkpointing
    pipeline = create_pipeline(checkpoint_enabled=True)
    pipeline.process_events(test_data[:500000])
    
    # Simulate crash
    checkpoint_path = pipeline.checkpoint_manager.last_checkpoint
    pipeline.force_kill()
    
    # Recovery
    recovered_pipeline = create_pipeline(recover_from=checkpoint_path)
    recovered_pipeline.process_events(test_data[500000:])
    
    # Verify no data loss
    assert verify_output_continuity()
```

### Technical Constraints

**Storage Requirements**:
- Checkpoint size: ~50-100MB per symbol
- Keep only last 3 checkpoints
- Use Parquet for efficient columnar storage

**Compatibility**:
- Must work with existing multi-symbol architecture
- Maintain backward compatibility for single-symbol mode
- Support both streaming and batch processing modes

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-07-24 | 1.0 | Initial story creation based on Epic 2 requirements and architecture research | Scrum Master |

## Dev Agent Record
### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results